### Title: Toward Unpaired Multi-modal Medical Image Segmentation via Learning Structured Semantic Consistency
* Paper ID: 2206.10571v1
* Paper URL: [http://arxiv.org/abs/2206.10571v1](http://arxiv.org/abs/2206.10571v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Integrating multi-modal data to improve medical image analysis has received
great attention recently. However, due to the modal discrepancy, how to use a
single model to process the data from multiple modalities is still an open
issue. In this paper, we propose a novel scheme to achieve better pixel-level
segmentation for unpaired multi-modal medical images. Different from previous
methods which adopted both modality-specific and modality-shared modules to
accommodate the appearance variance of different modalities while extracting
the common semantic information, our method is based on a single Transformer
with a carefully designed External Attention Module (EAM) to learn the
structured semantic consistency (i.e. semantic class representations and their
correlations) between modalities in the training phase. In practice, the
above-mentioned structured semantic consistency across modalities can be
progressively achieved by implementing the consistency regularization at the
modality-level and image-level respectively. The proposed EAMs are adopted to
learn the semantic consistency for different scale representations and can be
discarded once the model is optimized. Therefore, during the testing phase, we
only need to maintain one Transformer for all modal predictions, which nicely
balances the model's ease of use and simplicity. To demonstrate the
effectiveness of the proposed method, we conduct the experiments on two medical
image segmentation scenarios: (1) cardiac structure segmentation, and (2)
abdominal multi-organ segmentation. Extensive results show that the proposed
method outperforms the state-of-the-art methods by a wide margin, and even
achieves competitive performance with extremely limited training samples (e.g.,
1 or 3 annotated CT or MRI images) for one specific modality.

### Title: Learning to Estimate and Refine Fluid Motion with Physical Dynamics
* Paper ID: 2206.10480v1
* Paper URL: [http://arxiv.org/abs/2206.10480v1](http://arxiv.org/abs/2206.10480v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Extracting information on fluid motion directly from images is challenging.
Fluid flow represents a complex dynamic system governed by the Navier-Stokes
equations. General optical flow methods are typically designed for rigid body
motion, and thus struggle if applied to fluid motion estimation directly.
Further, optical flow methods only focus on two consecutive frames without
utilising historical temporal information, while the fluid motion (velocity
field) can be considered a continuous trajectory constrained by time-dependent
partial differential equations (PDEs). This discrepancy has the potential to
induce physically inconsistent estimations. Here we propose an unsupervised
learning based prediction-correction scheme for fluid flow estimation. An
estimate is first given by a PDE-constrained optical flow predictor, which is
then refined by a physical based corrector. The proposed approach outperforms
optical flow methods and shows competitive results compared to existing
supervised learning based methods on a benchmark dataset. Furthermore, the
proposed approach can generalize to complex real-world fluid scenarios where
ground truth information is effectively unknowable. Finally, experiments
demonstrate that the physical corrector can refine flow estimates by mimicking
the operator splitting method commonly utilised in fluid dynamical simulation.

### Title: Winning the Lottery Ahead of Time: Efficient Early Network Pruning
* Paper ID: 2206.10451v1
* Paper URL: [http://arxiv.org/abs/2206.10451v1](http://arxiv.org/abs/2206.10451v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Pruning, the task of sparsifying deep neural networks, received increasing
attention recently. Although state-of-the-art pruning methods extract highly
sparse models, they neglect two main challenges: (1) the process of finding
these sparse models is often very expensive; (2) unstructured pruning does not
provide benefits in terms of GPU memory, training time, or carbon emissions. We
propose Early Compression via Gradient Flow Preservation (EarlyCroP), which
efficiently extracts state-of-the-art sparse models before or early in training
addressing challenge (1), and can be applied in a structured manner addressing
challenge (2). This enables us to train sparse networks on commodity GPUs whose
dense versions would be too large, thereby saving costs and reducing hardware
requirements. We empirically show that EarlyCroP outperforms a rich set of
baselines for many tasks (incl. classification, regression) and domains (incl.
computer vision, natural language processing, and reinforcment learning).
EarlyCroP leads to accuracy comparable to dense training while outperforming
pruning baselines.

### Title: Secret key generation from Gaussian sources using lattice-based extractors
* Paper ID: 2206.10443v1
* Paper URL: [http://arxiv.org/abs/2206.10443v1](http://arxiv.org/abs/2206.10443v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We propose a lattice-based scheme for secret key generation from Gaussian
sources in the presence of an eavesdropper, and show that it achieves the
strong secret key capacity in the case of degraded source models, as well as
the optimal secret key / public communication rate trade-off. The key
ingredients of our scheme are a lattice extractor to extract the channel
intrinsic randomness, based on the notion of flatness factor, together with a
randomized lattice quantization technique to quantize the continuous source.
Compared to previous works, we introduce two new notions of flatness factor
based on $L^1$ distance and KL divergence, respectively, which are of
independent interest. We prove the existence of secrecy-good lattices under
$L^1$ distance and KL divergence, whose $L^1$ and KL flatness factors vanish
for volume-to-noise ratios up to $2\pi e$. This improves upon the
volume-to-noise ratio threshold $2\pi$ of the $L^{\infty}$ flatness factor.

### Title: Multilayer Block Models for Exploratory Analysis of Computer Event Logs
* Paper ID: 2206.10413v1
* Paper URL: [http://arxiv.org/abs/2206.10413v1](http://arxiv.org/abs/2206.10413v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We investigate a graph-based approach to exploratory data analysis in the
context of network security monitoring. Given a possibly large batch of event
logs describing ongoing activity, we first represent these events as a
bipartite multiplex graph. We then apply a model-based biclustering algorithm
to extract relevant clusters of entities and interactions between these
clusters, thereby providing a simplified situational picture. We illustrate
this methodology through two case studies addressing network flow records and
authentication logs, respectively. In both cases, the inferred clusters reveal
the functional roles of entities as well as relevant behavioral patterns.
Displaying interactions between these clusters also helps uncover malicious
activity. Our code is available at
https://github.com/cl-anssi/MultilayerBlockModels.

### Title: TabText: a Systematic Approach to Aggregate Knowledge Across Tabular Data Structures
* Paper ID: 2206.10381v1
* Paper URL: [http://arxiv.org/abs/2206.10381v1](http://arxiv.org/abs/2206.10381v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Processing and analyzing tabular data in a productive and efficient way is
essential for building successful applications of machine learning in fields
such as healthcare. However, the lack of a unified framework for representing
and standardizing tabular information poses a significant challenge to
researchers and professionals alike. In this work, we present TabText, a
methodology that leverages the unstructured data format of language to encode
tabular data from different table structures and time periods efficiently and
accurately. We show using two healthcare datasets and four prediction tasks
that features extracted via TabText outperform those extracted with traditional
processing methods by 2-5%. Furthermore, we analyze the sensitivity of our
framework against different choices for sentence representations of missing
values, meta information and language descriptiveness, and provide insights
into winning strategies that improve performance.

### Title: Can process mining help in anomaly-based intrusion detection?
* Paper ID: 2206.10379v1
* Paper URL: [http://arxiv.org/abs/2206.10379v1](http://arxiv.org/abs/2206.10379v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: In this paper, we consider the naive applications of process mining in
network traffic comprehension, traffic anomaly detection, and intrusion
detection. We standardise the procedure of transforming packet data into an
event log. We mine multiple process models and analyse the process models mined
with the inductive miner using ProM and the fuzzy miner using Disco. We compare
the two types of process models extracted from event logs of differing sizes.
We contrast the process models with the RFC TCP state transition diagram and
the diagram by Bishop et al. We analyse the issues and challenges associated
with process mining in intrusion detection and explain why naive process mining
with network data is ineffective.

### Title: Thermal Correction to Entanglement Spectrum for Conformal Field Theories
* Paper ID: 2206.10285v1
* Paper URL: [http://arxiv.org/abs/2206.10285v1](http://arxiv.org/abs/2206.10285v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We calculate the thermal correction to the entanglement spectrum for
separating a single interval of two dimensional conformal field theories. Our
derivation is a direct extension of the thermal correction to the R\'enyi
entropy. Within a low-temperature expansion by including only the first excited
state in the thermal density matrix, we approach analytical results of the
thermal correction to the entanglement spectrum at both of the small and large
interval limit. We find the temperature correction reduces the large
eigenvalues in the entanglement spectrum while increases the small eigenvalues
in the entanglement spectrum, leading to an overall crossover changing pattern
of the entanglement spectrum. Crucially, at low-temperature limit, the thermal
corrections are dominated by the first excited state and depend on its scaling
dimension $\Delta$ and degeneracy $g$. This opens an avenue to extract
universal information of underlying conformal data via the thermal entanglement
spectrum. All of these analytical computation is supported from numerical
simulations using 1+1 dimensional free fermion. Finally, we extend our
calculation to resolve the thermal correction to the symmetry-resolved
entanglement spectrum.

### Title: Dynamical Triplet Unravelling: A quantum Monte Carlo algorithm for reversible dynamics
* Paper ID: 2206.10283v1
* Paper URL: [http://arxiv.org/abs/2206.10283v1](http://arxiv.org/abs/2206.10283v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We introduce a quantum Monte Carlo method to simulate the reversible dynamics
of correlated many-body systems. Our method is based on the Laplace transform
of the time-evolution operator which, as opposed to most quantum Monte Carlo
methods, makes it possible to access the dynamics at longer times. The Monte
Carlo trajectories are realised through a piece-wise stochastic-deterministic
reversible evolution where free dynamics is interspersed with two-process
quantum jumps. The dynamical sign problem is bypassed via the so-called
deadweight approximation, which stabilizes the many-body phases at longer
times. We benchmark our method by simulating spin excitation propagation in the
XXZ model and dynamical confinement in the quantum Ising chain, and show how to
extract dynamical information from the Laplace representation.

### Title: Human-in-the-loop Speaker Adaptation for DNN-based Multi-speaker TTS
* Paper ID: 2206.10256v1
* Paper URL: [http://arxiv.org/abs/2206.10256v1](http://arxiv.org/abs/2206.10256v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: This paper proposes a human-in-the-loop speaker-adaptation method for
multi-speaker text-to-speech. With a conventional speaker-adaptation method, a
target speaker's embedding vector is extracted from his/her reference speech
using a speaker encoder trained on a speaker-discriminative task. However, this
method cannot obtain an embedding vector for the target speaker when the
reference speech is unavailable. Our method is based on a human-in-the-loop
optimization framework, which incorporates a user to explore the
speaker-embedding space to find the target speaker's embedding. The proposed
method uses a sequential line search algorithm that repeatedly asks a user to
select a point on a line segment in the embedding space. To efficiently choose
the best speech sample from multiple stimuli, we also developed a system in
which a user can switch between multiple speakers' voices for each phoneme
while looping an utterance. Experimental results indicate that the proposed
method can achieve comparable performance to the conventional one in objective
and subjective evaluations even if reference speech is not used as the input of
a speaker encoder directly.

### Title: Document Navigability: A Need for Print-Impaired
* Paper ID: 2206.10253v1
* Paper URL: [http://arxiv.org/abs/2206.10253v1](http://arxiv.org/abs/2206.10253v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Printed documents continue to be a challenge for blind, low-vision, and other
print-disabled (BLV) individuals. In this paper, we focus on the specific
problem of (in-)accessibility of internal references to citations, footnotes,
figures, tables and equations. While sighted users can flip to the referenced
content and flip back in seconds, linear audio narration that BLV individuals
rely on makes following these references extremely hard. We propose a vision
based technique to locate the referenced content and extract metadata needed to
(in subsequent work) inline a content summary into the audio narration. We
apply our technique to citations in scientific documents and find it works well
both on born-digital as well as scanned documents.

### Title: COREQQA -- A COmpliance REQuirements Understanding using Question Answering Tool
* Paper ID: 2206.10233v1
* Paper URL: [http://arxiv.org/abs/2206.10233v1](http://arxiv.org/abs/2206.10233v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We introduce COREQQA, a tool for assisting requirements engineers in
acquiring a better understanding of compliance requirements by means of
automated Question Answering. Extracting compliance-related requirements by
manually navigating through a legal document is both time-consuming and
error-prone. COREQQA enables requirements engineers to pose questions in
natural language about a compliance-related topic given some legal document,
e.g., asking about data breach. The tool then automatically navigates through
the legal document and returns to the requirements engineer a list of text
passages containing the possible answers to the input question. For better
readability, the tool also highlights the likely answers in these passages. The
engineer can then use this output for specifying compliance requirements.
COREQQA is developed using advanced large-scale language models from BERT's
family. COREQQA has been evaluated on four legal documents. The results of this
evaluation are briefly presented in the paper. The tool is publicly available
on Zenodo (DOI: 10.5281/zenodo.6653514).

### Title: WikiDoMiner: Wikipedia Domain-specific Miner
* Paper ID: 2206.10218v1
* Paper URL: [http://arxiv.org/abs/2206.10218v1](http://arxiv.org/abs/2206.10218v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We introduce WikiDoMiner, a tool for automatically generating domain-specific
corpora by crawling Wikipedia. WikiDoMiner helps requirements engineers create
an external knowledge resource that is specific to the underlying domain of a
given requirements specification (RS). Being able to build such a resource is
important since domain-specific datasets are scarce. WikiDoMiner generates a
corpus by first extracting a set of domain-specific keywords from a given RS,
and then querying Wikipedia for these keywords. The output of WikiDoMiner is a
set of Wikipedia articles relevant to the domain of the input RS. Mining
Wikipedia for domain-specific knowledge can be beneficial for multiple
requirements engineering tasks, e.g., ambiguity handling, requirements
classification, and question answering. WikiDoMiner is publicly available on
Zenodo under an open-source license (DOI: 10.5281/zenodo.6671357).

### Title: TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks
* Paper ID: 2206.10177v1
* Paper URL: [http://arxiv.org/abs/2206.10177v1](http://arxiv.org/abs/2206.10177v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Spiking Neural Networks (SNNs) is a practical approach toward more
data-efficient deep learning by simulating neurons leverage on temporal
information. In this paper, we propose the Temporal-Channel Joint Attention
(TCJA) architectural unit, an efficient SNN technique that depends on attention
mechanisms, by effectively enforcing the relevance of spike sequence along both
spatial and temporal dimensions. Our essential technical contribution lies on:
1) compressing the spike stream into an average matrix by employing the squeeze
operation, then using two local attention mechanisms with an efficient 1-D
convolution to establish temporal-wise and channel-wise relations for feature
extraction in a flexible fashion. 2) utilizing the Cross Convolutional Fusion
(CCF) layer for modeling inter-dependencies between temporal and channel scope,
which breaks the independence of the two dimensions and realizes the
interaction between features. By virtue of jointly exploring and recalibrating
data stream, our method outperforms the state-of-the-art (SOTA) by up to 15.7%
in terms of top-1 classification accuracy on all tested mainstream static and
neuromorphic datasets, including Fashion-MNIST, CIFAR10-DVS, N-Caltech 101, and
DVS128 Gesture.

### Title: A Multi-grained based Attention Network for Semi-supervised Sound Event Detection
* Paper ID: 2206.10175v1
* Paper URL: [http://arxiv.org/abs/2206.10175v1](http://arxiv.org/abs/2206.10175v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Sound event detection (SED) is an interesting but challenging task due to the
scarcity of data and diverse sound events in real life. This paper presents a
multi-grained based attention network (MGA-Net) for semi-supervised sound event
detection. To obtain the feature representations related to sound events, a
residual hybrid convolution (RH-Conv) block is designed to boost the vanilla
convolution's ability to extract the time-frequency features. Moreover, a
multi-grained attention (MGA) module is designed to learn temporal resolution
features from coarse-level to fine-level. With the MGA module,the network could
capture the characteristics of target events with short- or long-duration,
resulting in more accurately determining the onset and offset of sound events.
Furthermore, to effectively boost the performance of the Mean Teacher (MT)
method, a spatial shift (SS) module as a data perturbation mechanism is
introduced to increase the diversity of data. Experimental results show that
the MGA-Net outperforms the published state-of-the-art competitors, achieving
53.27% and 56.96% event-based macro F1 (EB-F1) score, 0.709 and 0.739
polyphonic sound detection score (PSDS) on the validation and public set
respectively.

### Title: Complex Network Analysis of a Graphic Novel: The Case of the Bande Dessin{Ã©}e Thorgal
* Paper ID: 2206.10162v1
* Paper URL: [http://arxiv.org/abs/2206.10162v1](http://arxiv.org/abs/2206.10162v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: The task of extracting and analyzing character networks from works of
fiction, such as novels and movies, has been the object of a number of recent
publications. However, only a very few of them focus on graphic novels, and
even fewer on European graphic novels. In this article, we focus on Thorgal, a
bande dessin{\'e}e, i.e. a comic of the French-Belgian tradition. We manually
annotate all the volumes of this series, in order to constitute a corpus
allowing us to extract its character network. We perform a descriptive analysis
of the network structure and compare it to real-world and fictional social
networks. We also study the effect of character filtering over the network
structure. Finally, we leverage complex network analysis tools to answer two
research questions from the literature, related to the similarity between
Thorgal and the Saga of Icelanders; and to the position of women in the series.
Our data and source code are both publicly available online.

### Title: Open-Source Framework for Encrypted Internet and Malicious Traffic Classification
* Paper ID: 2206.10144v1
* Paper URL: [http://arxiv.org/abs/2206.10144v1](http://arxiv.org/abs/2206.10144v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Internet traffic classification plays a key role in network visibility,
Quality of Services (QoS), intrusion detection, Quality of Experience (QoE) and
traffic-trend analyses. In order to improve privacy, integrity,
confidentiality, and protocol obfuscation, the current traffic is based on
encryption protocols, e.g., SSL/TLS. With the increased use of Machine-Learning
(ML) and Deep-Learning (DL) models in the literature, comparison between
different models and methods has become cumbersome and difficult due to a lack
of a standardized framework. In this paper, we propose an open-source
framework, named OSF-EIMTC, which can provide the full pipeline of the learning
process. From the well-known datasets to extracting new and well-known
features, it provides implementations of well-known ML and DL models (from the
traffic classification literature) as well as evaluations. Such a framework can
facilitate research in traffic classification domains, so that it will be more
repeatable, reproducible, easier to execute, and will allow a more accurate
comparison of well-known and novel features and models. As part of our
framework evaluation, we demonstrate a variety of cases where the framework can
be of use, utilizing multiple datasets, models, and feature sets. We show
analyses of publicly available datasets and invite the community to participate
in our open challenges using the OSF-EIMTC.

### Title: Automatic Concept Extraction for Concept Bottleneck-based Video Classification
* Paper ID: 2206.10129v1
* Paper URL: [http://arxiv.org/abs/2206.10129v1](http://arxiv.org/abs/2206.10129v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Recent efforts in interpretable deep learning models have shown that
concept-based explanation methods achieve competitive accuracy with standard
end-to-end models and enable reasoning and intervention about extracted
high-level visual concepts from images, e.g., identifying the wing color and
beak length for bird-species classification. However, these concept bottleneck
models rely on a necessary and sufficient set of predefined concepts-which is
intractable for complex tasks such as video classification. For complex tasks,
the labels and the relationship between visual elements span many frames, e.g.,
identifying a bird flying or catching prey-necessitating concepts with various
levels of abstraction. To this end, we present CoDEx, an automatic Concept
Discovery and Extraction module that rigorously composes a necessary and
sufficient set of concept abstractions for concept-based video classification.
CoDEx identifies a rich set of complex concept abstractions from natural
language explanations of videos-obviating the need to predefine the amorphous
set of concepts. To demonstrate our method's viability, we construct two new
public datasets that combine existing complex video classification datasets
with short, crowd-sourced natural language explanations for their labels. Our
method elicits inherent complex concept abstractions in natural language to
generalize concept-bottleneck methods to complex tasks.

### Title: Supervision-Guided Codebooks for Masked Prediction in Speech Pre-training
* Paper ID: 2206.10125v1
* Paper URL: [http://arxiv.org/abs/2206.10125v1](http://arxiv.org/abs/2206.10125v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Recently, masked prediction pre-training has seen remarkable progress in
self-supervised learning (SSL) for speech recognition. It usually requires a
codebook obtained in an unsupervised way, making it less accurate and difficult
to interpret. We propose two supervision-guided codebook generation approaches
to improve automatic speech recognition (ASR) performance and also the
pre-training efficiency, either through decoding with a hybrid ASR system to
generate phoneme-level alignments (named PBERT), or performing clustering on
the supervised speech features extracted from an end-to-end CTC model (named
CTC clustering). Both the hybrid and CTC models are trained on the same small
amount of labeled speech as used in fine-tuning. Experiments demonstrate
significant superiority of our methods to various SSL and self-training
baselines, with up to 17.0% relative WER reduction. Our pre-trained models also
show good transferability in a non-ASR speech task.

### Title: General Framework for Reversible Data Hiding in Texts Based on Masked Language Modeling
* Paper ID: 2206.10112v1
* Paper URL: [http://arxiv.org/abs/2206.10112v1](http://arxiv.org/abs/2206.10112v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: With the fast development of natural language processing, recent advances in
information hiding focus on covertly embedding secret information into texts.
These algorithms either modify a given cover text or directly generate a text
containing secret information, which, however, are not reversible, meaning that
the original text not carrying secret information cannot be perfectly recovered
unless much side information are shared in advance. To tackle with this
problem, in this paper, we propose a general framework to embed secret
information into a given cover text, for which the embedded information and the
original cover text can be perfectly retrieved from the marked text. The main
idea of the proposed method is to use a masked language model to generate such
a marked text that the cover text can be reconstructed by collecting the words
of some positions and the words of the other positions can be processed to
extract the secret information. Our results show that the original cover text
and the secret information can be successfully embedded and extracted.
Meanwhile, the marked text carrying secret information has good fluency and
semantic quality, indicating that the proposed method has satisfactory
security, which has been verified by experimental results. Furthermore, there
is no need for the data hider and data receiver to share the language model,
which significantly reduces the side information and thus has good potential in
applications.

### Title: Automatic Controllable Product Copywriting for E-Commerce
* Paper ID: 2206.10103v1
* Paper URL: [http://arxiv.org/abs/2206.10103v1](http://arxiv.org/abs/2206.10103v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Automatic product description generation for e-commerce has witnessed
significant advancement in the past decade. Product copywriting aims to attract
users' interest and improve user experience by highlighting product
characteristics with textual descriptions. As the services provided by
e-commerce platforms become diverse, it is necessary to adapt the patterns of
automatically-generated descriptions dynamically. In this paper, we report our
experience in deploying an E-commerce Prefix-based Controllable Copywriting
Generation (EPCCG) system into the JD.com e-commerce product recommendation
platform. The development of the system contains two main components: 1)
copywriting aspect extraction; 2) weakly supervised aspect labeling; 3) text
generation with a prefix-based language model; 4) copywriting quality control.
We conduct experiments to validate the effectiveness of the proposed EPCCG. In
addition, we introduce the deployed architecture which cooperates with the
EPCCG into the real-time JD.com e-commerce recommendation platform and the
significant payoff since deployment.

### Title: Reconstruct from Top View: A 3D Lane Detection Approach based on Geometry Structure Prior
* Paper ID: 2206.10098v1
* Paper URL: [http://arxiv.org/abs/2206.10098v1](http://arxiv.org/abs/2206.10098v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: In this paper, we propose an advanced approach in targeting the problem of
monocular 3D lane detection by leveraging geometry structure underneath the
process of 2D to 3D lane reconstruction. Inspired by previous methods, we first
analyze the geometry heuristic between the 3D lane and its 2D representation on
the ground and propose to impose explicit supervision based on the structure
prior, which makes it achievable to build inter-lane and intra-lane
relationships to facilitate the reconstruction of 3D lanes from local to
global. Second, to reduce the structure loss in 2D lane representation, we
directly extract top view lane information from front view images, which
tremendously eases the confusion of distant lane features in previous methods.
Furthermore, we propose a novel task-specific data augmentation method by
synthesizing new training data for both segmentation and reconstruction tasks
in our pipeline, to counter the imbalanced data distribution of camera pose and
ground slope to improve generalization on unseen data. Our work marks the first
attempt to employ the geometry prior information into DNN-based 3D lane
detection and makes it achievable for detecting lanes in an extra-long
distance, doubling the original detection range. The proposed method can be
smoothly adopted by other frameworks without extra costs. Experimental results
show that our work outperforms state-of-the-art approaches by 3.8% F-Score on
Apollo 3D synthetic dataset at real-time speed of 82 FPS without introducing
extra parameters.

### Title: Counting Varying Density Crowds Through Density Guided Adaptive Selection CNN and Transformer Estimation
* Paper ID: 2206.10075v1
* Paper URL: [http://arxiv.org/abs/2206.10075v1](http://arxiv.org/abs/2206.10075v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: In real-world crowd counting applications, the crowd densities in an image
vary greatly. When facing with density variation, human tend to locate and
count the target in low-density regions, and reason the number in high-density
regions. We observe that CNN focus on the local information correlation using a
fixed-size convolution kernel and the Transformer could effectively extract the
semantic crowd information by using the global self-attention mechanism. Thus,
CNN could locate and estimate crowd accurately in low-density regions, while it
is hard to properly perceive density in high-density regions. On the contrary,
Transformer, has a high reliability in high-density regions, but fails to
locate the target in sparse regions. Neither CNN or Transformer can well deal
with this kind of density variations. To address this problem, we propose a CNN
and Transformer Adaptive Selection Network (CTASNet) which can adaptively
select the appropriate counting branch for different density regions. Firstly,
CTASNet generates the prediction results of CNN and Transformer. Then,
considering that CNN/Transformer are appropriate for low/high-density regions,
a density guided Adaptive Selection Module is designed to automatically combine
the predictions of CNN and Transformer. Moreover, to reduce the influences of
annotation noise, we introduce a Correntropy based Optimal Transport loss.
Extensive experiments on four challenging crowd counting datasets have
validated the proposed method.

